syntax = "proto3";
package api;

import "google/api/annotations.proto";
import "protoc-gen-openapiv2/options/annotations.proto";

option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_swagger) = {
  info: {
    title: "embedds";
    version: "1.0.0";
    contact: {
      name: "anansi";
      url: "https://github.com/infrawhispers/anansi";
      email: "infrawhispers@proton.me";
    };
    license: {
      name: "Apache 2.0 License";
      url: "https://github.com/infrawhispers/anansi/blob/main/LICENSE"
    };
  };
  schemes: HTTPS;
};

message InitializeModelRequest {
  repeated ModelSettings models = 1 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {
    description: "A list of models to be initialized"
    example: '[{"model_name": "M_INSTRUCTOR_BASE", "num_threads": 4, "parallel_execution": true}]'
  }];
}

message ModelSettings {
  option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_schema) = {
    json_schema: {
      description:
        "Configuration settings for the instantiaion of an onnx "
        "model"
      required: ["model_name"]
    }
  };
  ModelClass model_class = 1 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "corresponding class in which the model_name belongs to"}];
  string model_name = 2 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "specific name of the model to apply the encoding transformation"}];
  uint32 num_threads = 3 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description:
      "The number of threads to parallelize the execution of "
      "the graph - if the graph can be parallelized. <br/> If "
      "unset, defaults to the available parallelism on the "
      "underlying machine."
}];
  bool parallel_execution = 4 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description:
      "Enable/disable the parallel execution of the graph. "
      "Parallel execution can improve model execution speed at "
      "the cost of increased memory usage."
}];
}

enum EncodingModelDevice {
  MD_UNKNOWN = 0;
  MD_CPU = 1;
  MD_CUDA = 2;
  MD_TENSOR = 3;
}

message InitializeModelResponse {
  repeated ModelInitResult results = 1;
}
message ModelInitResult {
  option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_schema) = {
    json_schema: {
      description:
        "Configuration settings for the instantiaion of an onnx "
        "model";
      read_only: true
    }
  };
  ModelClass model_class = 1 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "corresponding class in which the model_name belongs to"}];
  string model_name = 2 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "specific name of the model to apply the encoding transformation"}];
  bool initialized = 3 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "whether or not the model was successfully initalized"}];
  string err_message = 4 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "error details outlining why the model could not be initialized"}];
}
enum ModelClass {
  ModelClass_Unknown = 0;
  ModelClass_CLIP = 1;
  ModelClass_INSTRUCTOR = 2;
}

message EncodeItem {
  option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_schema) = {
    json_schema: {
      description:
        "Minimal encoding unit associating a piece of content "
        "[text, image, image_uri] with a selected model"
      required: ["model"]
    }
  };
  ModelClass model_class = 1 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "corresponding class in which the model_name belongs to"}];
  string model_name = 2 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "specific name of the model to apply the encoding transformation"}];
  repeated string text = 3 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "repeated text to encode"}];
  repeated string instructions = 4 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description:
      "a list of instructions to pass to ```INSTRUCTOR``` "
      "based models"
}];
  repeated bytes image = 5 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "repeated raw jpeg bytes"}];
  repeated string image_uri = 6 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "repeated uris to fetch image data from"}];
}
message EncodeRequest {
  option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_schema) = {example: '{"data":[{"model_class":"ModelClass_INSTRUCTOR","model_name":"INSTRUCTOR_LARGE", "text":["3D ActionSLAM: wearable person tracking ...","Inside Gohar World and the Fine, Fantastical Art"],"instructions":["Represent the Science title:","Represent the Magazine title:"]}]}'};
  repeated EncodeItem data = 1 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "repeated data items to generate encodings for"}];
}

message EncodeResult {
  string err_message = 1 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "explanation for why the content could not be encoded"}];
  repeated float embedding = 2 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description: "embedding representation of the the content"}];
}
message EncodeResponse {
  repeated EncodeResult results = 1 [(grpc.gateway.protoc_gen_openapiv2.options.openapiv2_field) = {description:
      "list of embedding results corresponding to the ordered "
      "content submitted"
}];
}

service Api {
  rpc Encode(EncodeRequest) returns (EncodeResponse) {
    option (google.api.http) = {
      post: "/encode"
      body: "*"
    };
    option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_operation) = {
      summary: "encode";
      description:
        "Generates a vector representation of text or images using the specified embedding model. "
        "If the model does not exist or has not been loaded, an error will be returned for that particular data item. "
        "<br/><br/>It is recommended that multiple pieces of content are specified in a single request to take advantage of batching, "
        "especially when running under with a GPU accelerated <a href='https://onnxruntime.ai/docs/execution-providers/' target='_blank'>ExecutionProvider.</a> "
        "Recommended sizes can be found at <a href='/embedds/supported-models' target='_blank'>embedds/model-details</a> and embedds will "
        "attempt to split and batch encoding requests."
        "<br/>----<br/>"
        "<b>Not all models support [text, instructions, image, image_uri]</b> a breakdown of present support is outlined below:"
        "<ul>"
        "<li>ModelClass_INSTRUCTOR - requires: {text, instructions}</li>"
        "<li>ModelClass_CLIP - any_of: {text, image_uri, image}</li>"
        "</ul>"
        "";
      consumes: "application/json";
      produces: "application/json";
    };
  }

  rpc InitializeModel(InitializeModelRequest) returns (InitializeModelResponse) {
    option (google.api.http) = {
      post: "/initalize_models"
      body: "*"
    };
    option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_operation) = {
      summary: "initialize_models";
      description:
        "Intializes an onnx model, adding it to the pool of models available for embedding generation. "
        "ONNX models are loaded from the folder designated by ```EMBBEDDS_CACHE_FOLDER``` and it is recommended "
        "that this folder be volume mounted if running within a container."
        "<br/><br/>If the model is missing, the server will attempt to download the corresponding file from a remote source."
        "<br/><br/>embedds must be created with ```EMBEDDS_ALLOW_ADMIN=true``` as the unrestricted creation of models can lead "
        "to resource starvation. If you are exposing the process to non-trusted clients, we recommended that ```EMBEDDS_ALLOW_ADMIN```"
        " be set to false.";
      consumes: "application/json";
      produces: "application/json";
    };
  }
}
